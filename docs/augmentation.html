---

title: Title

keywords: fastai
sidebar: home_sidebar

summary: "summary"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/02_augmentation.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
    {% raw %}
        
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Augmenting-the-images">Augmenting the images<a class="anchor-link" href="#Augmenting-the-images">&#182;</a></h2><p>So we have a set of labelled images of Pokemon Cards that can form a training set. However there are some practical problems with using the set as is.</p>
<p>For some cards our set is somewhat analgous to the infamous Dog Breeds data set. For example, the Charizard card above we have the same character but with differences in pose and colouring. which seems analogous to dog breeds data set. But for most characters we only have one example.</p>
<p>The practical problem in terms of training a neural net here is how do we split this set into training and validation if we had only one example of a given class?</p>
<p>This highlights that ways in which this problem is different to the dog breeds set. In one sense we will only be collecting images of actual pokemon cards that should - in terms of depicted content - match exactly one of the downloaded images.</p>
<p>But you would expect variation in between images captured of a card e.g. on a phone. For example, difference in lighting condidtions, orientations of the card, background.</p>
<p>So set about augmenting the original images to account for likely variations in taking images of cards. Produce enough of these variations to provide a training and validation set: So make 50 slightly different images of each pokemon card, with different lighting, skew, rotation, clipping as if they were images of pokemon cards captured in the wild. Then should have enough to split into training and validation sets and proceed.</p>
<p>This is a common situation in training self driving cars. Which is where I borrowed the code from.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="augment_brightness_camera_images" class="doc_header"><code>augment_brightness_camera_images</code><a href="https://github.com/wooduk/pokedexr/tree/master/pokedexr/augmentation.py#L10" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>augment_brightness_camera_images</code>(<strong><code>image</code></strong>, <strong><code>brightness</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="transform_image" class="doc_header"><code>transform_image</code><a href="https://github.com/wooduk/pokedexr/tree/master/pokedexr/augmentation.py#L18" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>transform_image</code>(<strong><code>img</code></strong>, <strong><code>ang_range</code></strong>, <strong><code>shear_range</code></strong>, <strong><code>trans_range</code></strong>, <strong><code>brightness</code></strong>=<em><code>0</code></em>)</p>
</blockquote>
<p>This function transforms images to generate new images.
The function takes in following arguments,
1- Image
2- ang_range: Range of angles for rotation
3- shear_range: Range of values to apply affine transform to
4- trans_range: Range of values to apply translations over.</p>
<p>A Random uniform distribution is used to generate different parameters for transformation</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Let's pick a card where we only have one version and augment it to synthetically create something that looks like a set of images of a card that might be captured on a phone.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">N_AUGMENTED_IMAGES</span> <span class="o">=</span> <span class="mi">10</span>

<span class="n">f</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>

<span class="n">src_img_url</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">image_record</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;Bewear_(GX_Starter_Deck_63)&#39;</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;http:</span><span class="si">{src_img_url}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="n">src_img</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">BytesIO</span><span class="p">(</span><span class="n">r</span><span class="o">.</span><span class="n">content</span><span class="p">),</span><span class="mi">0</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">N_AUGMENTED_IMAGES</span><span class="p">):</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">transform_image</span><span class="p">(</span><span class="n">src_img</span><span class="p">,</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="n">brightness</span><span class="o">=</span><span class="mf">0.50</span><span class="p">)</span>
    <span class="n">a</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="o">//</span><span class="mi">5</span><span class="p">,</span><span class="n">i</span><span class="o">%</span><span class="k">5</span>]
    <span class="n">a</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
    <span class="n">a</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">a</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That black background doesn't look so ~hot~ realistic. Perhaps I can graft in some backgrounds onto the black spaces.</p>
<p>I manually found a few images that could represent tables, parts of rooms etc and saved them to GDrive and made them publicly accesible. Let's fetch them here and then write a bit of code to graft them onto the example images.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="fetch_background_images" class="doc_header"><code>fetch_background_images</code><a href="https://github.com/wooduk/pokedexr/tree/master/pokedexr/augmentation.py#L91" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>fetch_background_images</code>(<strong><code>src</code></strong>=<em><code>'https://pokedexproject.s3.eu-west-2.amazonaws.com/background_images/'</code></em>, <strong><code>n_images</code></strong>=<em><code>15</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">fetch_background_images</span><span class="p">()</span>

<span class="n">f</span><span class="p">,</span><span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span><span class="mi">7</span><span class="p">))</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">bkgimg</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">background_images</span><span class="p">):</span>
    <span class="n">a</span><span class="o">=</span><span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="o">//</span><span class="mi">5</span><span class="p">,</span><span class="n">i</span><span class="o">%</span><span class="k">5</span>]
    <span class="n">a</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">bkgimg</span><span class="p">)</span>
    <span class="n">a</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">bkgimg</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">a</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s1">&#39;off&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">

</div>
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="apply_random_background" class="doc_header"><code>apply_random_background</code><a href="https://github.com/wooduk/pokedexr/tree/master/pokedexr/augmentation.py#L104" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>apply_random_background</code>(<strong><code>img</code></strong>, <strong><code>background_images</code></strong>)</p>
</blockquote>
<p>simple image compositor
select random background image from the set provided
img : target image (numpy array)
background_images: list of images (numpy array) as backgrounds</p>

</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And this is how it would be applied to an image.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">_</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">apply_random_background</span><span class="p">(</span><span class="n">img</span><span class="p">,</span><span class="n">background_images</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}
</div>
 

