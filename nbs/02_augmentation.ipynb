{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting the images\n",
    "\n",
    "So we have a set of labelled images of Pokemon Cards that can form a training set. However there are some practical problems with using the set as is. \n",
    "\n",
    "For some cards our set is somewhat analgous to the infamous Dog Breeds data set. For example, the Charizard card above we have the same character but with differences in pose and colouring. which seems analogous to dog breeds data set. But for most characters we only have one example.\n",
    "\n",
    "The practical problem in terms of training a neural net here is how do we split this set into training and validation if we had only one example of a given class?\n",
    "\n",
    "This highlights that ways in which this problem is different to the dog breeds set. In one sense we will only be collecting images of actual pokemon cards that should - in terms of depicted content - match exactly one of the downloaded images. \n",
    "\n",
    "But you would expect variation in between images captured of a card e.g. on a phone. For example, difference in lighting condidtions, orientations of the card, background. \n",
    "\n",
    "So set about augmenting the original images to account for likely variations in taking images of cards. Produce enough of these variations to provide a training and validation set: So make 50 slightly different images of each pokemon card, with different lighting, skew, rotation, clipping as if they were images of pokemon cards captured in the wild. Then should have enough to split into training and validation sets and proceed.\n",
    "\n",
    "This is a common situation in training self driving cars. Which is where I borrowed the code from.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "import cv2\n",
    "\n",
    "def augment_brightness_camera_images(image,brightness):\n",
    "    image1 = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    # I modified this to suit my needs\n",
    "    random_bright = brightness+np.random.uniform(low=0.0, high=1-brightness)\n",
    "    image1[:,:,2] = image1[:,:,2]*random_bright\n",
    "    image1 = cv2.cvtColor(image1,cv2.COLOR_HSV2RGB)\n",
    "    return image1\n",
    "\n",
    "def transform_image(img,ang_range,shear_range,trans_range,brightness=0):\n",
    "    '''\n",
    "    This function transforms images to generate new images.\n",
    "    The function takes in following arguments,\n",
    "    1- Image\n",
    "    2- ang_range: Range of angles for rotation\n",
    "    3- shear_range: Range of values to apply affine transform to\n",
    "    4- trans_range: Range of values to apply translations over.\n",
    "\n",
    "    A Random uniform distribution is used to generate different parameters for transformation\n",
    "\n",
    "    '''\n",
    "    \n",
    "    # zoom\n",
    "    height, width, channels = img.shape\n",
    "\n",
    "    #prepare the crop\n",
    "    scale=np.random.uniform(low=0.7, high=1.3)\n",
    "    \n",
    "    centerX,centerY=int(height/2),int(width/2)\n",
    "    radiusX,radiusY= int(np.round(scale*height/2)),int(np.round(scale*width/2))\n",
    "\n",
    "    minX,maxX=centerX-radiusX,centerX+radiusX\n",
    "    minY,maxY=centerY-radiusY,centerY+radiusY\n",
    "\n",
    "    if scale > 1:\n",
    "        # zoom out\n",
    "        new_image = np.zeros(((maxX-minX)+1, (maxY-minY)+1,3),dtype=np.uint8)\n",
    "        x0=-1*minX; y0=-1*minY\n",
    "        new_image[y0:y0+height,x0:x0+width,:]=img\n",
    "        img=new_image.copy()\n",
    "        \n",
    "    else:\n",
    "        cropped = img[minX:maxX, minY:maxY]\n",
    "        resized_cropped = cv2.resize(cropped, (width, height)) \n",
    "        img=resized_cropped\n",
    "    \n",
    "    # Rotation\n",
    "\n",
    "    ang_rot = np.random.uniform(ang_range)-ang_range/2\n",
    "    rows,cols,ch = img.shape    \n",
    "    Rot_M = cv2.getRotationMatrix2D((cols/2,rows/2),ang_rot,1)\n",
    "\n",
    "    # Translation\n",
    "    tr_x = trans_range*np.random.uniform()-trans_range/2\n",
    "    tr_y = trans_range*np.random.uniform()-trans_range/2\n",
    "    Trans_M = np.float32([[1,0,tr_x],[0,1,tr_y]])\n",
    "\n",
    "    # Shear\n",
    "    pts1 = np.float32([[5,5],[20,5],[5,20]])\n",
    "\n",
    "    pt1 = 5+shear_range*np.random.uniform()-shear_range/2\n",
    "    pt2 = 20+shear_range*np.random.uniform()-shear_range/2\n",
    "\n",
    "    # Brightness\n",
    "\n",
    "\n",
    "    pts2 = np.float32([[pt1,5],[pt2,pt1],[5,pt2]])\n",
    "\n",
    "    shear_M = cv2.getAffineTransform(pts1,pts2)\n",
    "\n",
    "    img = cv2.warpAffine(img,Rot_M,(cols,rows))\n",
    "    img = cv2.warpAffine(img,Trans_M,(cols,rows))\n",
    "    img = cv2.warpAffine(img,shear_M,(cols,rows))\n",
    "\n",
    "    if brightness != 0:\n",
    "      img = augment_brightness_camera_images(img,brightness)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's pick a card where we only have one version and augment it to synthetically create something that looks like a set of images of a card that might be captured on a phone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N_AUGMENTED_IMAGES = 10\n",
    "\n",
    "f,ax = plt.subplots(2,5, figsize=(14,7))\n",
    "\n",
    "src_img_url = list(image_record.get('Bewear_(GX_Starter_Deck_63)'))[0]\n",
    "r = requests.get(f'http:{src_img_url}')\n",
    "src_img = plt.imread(BytesIO(r.content),0)\n",
    "\n",
    "for i in range(N_AUGMENTED_IMAGES):\n",
    "    img = transform_image(src_img,20,5,10,brightness=0.50)\n",
    "    a=ax[i//5,i%5]\n",
    "    a.imshow(img)\n",
    "    a.set_title(img.shape[0:2])\n",
    "    a.axis('off')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That black background doesn't look so ~hot~ realistic. Perhaps I can graft in some backgrounds onto the black spaces.\n",
    "\n",
    "I manually found a few images that could represent tables, parts of rooms etc and saved them to GDrive and made them publicly accesible. Let's fetch them here and then write a bit of code to graft them onto the example images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "BKG_SRC = 'https://pokedexproject.s3.eu-west-2.amazonaws.com/background_images/'\n",
    "\n",
    "def fetch_background_images(src=BKG_SRC, n_images=15):\n",
    "    \n",
    "    background_images=[]\n",
    "    \n",
    "    for i in range(1, n_images+1):\n",
    "        r=requests.get(src+f'back{i}.jpg')\n",
    "        d=plt.imread(BytesIO(r.content),0)\n",
    "        background_images.append(d)\n",
    "\n",
    "    return background_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_background_images()\n",
    "\n",
    "f,ax = plt.subplots(3,5,figsize=(14,7))\n",
    "for i,bkgimg in enumerate(background_images):\n",
    "    a=ax[i//5,i%5]\n",
    "    a.imshow(bkgimg)\n",
    "    a.set_title(bkgimg.shape)\n",
    "    a.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export \n",
    "def apply_random_background(img,background_images):\n",
    "    \"\"\"\n",
    "    simple image compositor\n",
    "    select random background image from the set provided\n",
    "    img : target image (numpy array)\n",
    "    background_images: list of images (numpy array) as backgrounds\n",
    "    \"\"\"\n",
    "    img1 = img.copy()\n",
    "    N = len(background_images)\n",
    "    i = int(np.clip(np.round((N-1)*np.random.uniform()),0,N-1))\n",
    "    img2=np.array(Image.fromarray(background_images[i]).resize(Image.fromarray(img).size))\n",
    "    \n",
    "    # create mask for empty areas of target image\n",
    "    idx=(img<5)\n",
    "    \n",
    "    # copy background into those empty areas\n",
    "    print(img2.shape,img.shape)\n",
    "    img1[idx]=img2[idx]\n",
    "    \n",
    "    return img1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is how it would be applied to an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.imshow(apply_random_background(img,background_images))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
